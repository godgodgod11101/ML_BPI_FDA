---
title: "BPI Model Improvement"
author: "Jacky Wang"
format:
    html:
        theme: cosmo
        toc: true
        toc-depth: 2
        toc-location: right
        toc-title: "On this page"
        css: "css/style.css"
        df-print: paged
---



## Code Structure

1. 資料清理（DataWrangling.qmd）
2. 資料不平衡處理（HandlingImbData.qmd）
2. **模型配適（ModelFitting.qmd）**



## Introduction

本程式檔執行內容如下：

1. Import：引入資料，資料已進行清理與切分。
2. Handling Imbalanced Datasets：資料不平衡處理。



## Package

引入所需套件
```{r}
#| message: false
#| warning: false

# tidyverse
library(tibble)
library(dplyr)
library(purrr)    # FP toolkit，以map()、modify()取代for-loop

# tidymodels
library(parsnip)

```



## Import

```{r}
#| message: false
load("data/vegetable_imb.rda")
load("data/vegetable_fit.rda")
```



## Predict

```{r}

# function
ensemble_pred <- function(lst_fitmdls, tbl_test = lst_mdlData$test$test, thres = .5) {
    
    # 各模型預測結果
    lst_predprob <- map(
        .x = lst_fitmdls, 
        .f = \(x) {
            predict.model_fit(
                object = x, 
                new_data = tbl_test, 
                type = "prob"
            ) %>% 
                {.[[".pred_Fail"]]} %>%    # ROC curve 需預測機率
                {ifelse(. > thres, 1, 0)}    # 可考量調整閾值
        } 
    )
    
    # 投票法集成
    votethres <- length(lst_fitmdls) / 2
    predrsl_ensemble <- lst_predprob %>% 
        pmap_int(.l = ., .f = sum) %>% 
        {ifelse(.>votethres, "Fail", "Pass")} %>% 
        factor(levels = c("Fail", "Pass"))
    
    return(predrsl_ensemble)
}

```

```{r}
#| message: false
#| warning: false

# execute
tbl_truthpred <- tibble(
    `Truth` = lst_mdlData$test$test$Y, 
    `Model_Benchmark` = ensemble_pred(lst_fit$all), 
    `Model_130101` = ensemble_pred(lst_fit$`130101`), 
    `Model_140703` = ensemble_pred(lst_fit$`140703`)
)

```



## Evaluate

```{r}
library(yardstick)
library(ggplot2)
library(patchwork)    # 多圖合併呈現
library(tidyr)    # reshape data
```

### confusion matrix

```{r}

# function
plot_cfmx <- function(tbl_truthpred) {
    
    truth_col <- names(tbl_truthpred)[1]
    pred_cols <- names(tbl_truthpred)[c(-1)]    # 取2至最後
    
    plots_cfmx <- map(
        .x = pred_cols,    # atomic vector
        .f = \(x) {
            conf_mat(
                data = tbl_truthpred, 
                truth = all_of(truth_col),    # data-masking contexts is deprecated
                estimate = all_of(x)
            ) %>% 
            autoplot(type = "heatmap") + ggtitle(x)
        }
    )
    
    names(plots_cfmx) <- pred_cols
    
    return(plots_cfmx)
}

# execute
plots_cfmx <- plot_cfmx(tbl_truthpred)

# layout
plots_cfmx$Model_Benchmark | 
    (plots_cfmx$Model_130101 / plots_cfmx$Model_140703)


```

### metrics

```{r}

# function

#   combine metric function
multi_metric <- metric_set(f_meas, precision, recall)

#   use new function and tabulate
tabulate_metrics <- function(tbl_truthpred, func = multi_metric) {
    
    truth_col <- names(tbl_truthpred)[1]
    pred_cols <- names(tbl_truthpred)[c(-1)]    # 取2至最後
    
    tbl_estimates <- map(
        .x = pred_cols, 
        .f = \(x) func(
            data = tbl_truthpred, 
            truth = all_of(truth_col), 
            estimate = all_of(x)
        ) %>% 
            select(c(".metric", ".estimate")) %>% 
            add_column(`.model` = x, .before = 1)
    ) %>% 
        bind_rows() %>% 
        pivot_wider(names_from = ".metric", values_from = ".estimate")
    
    return(tbl_estimates)
}

# execute
tabulate_metrics(tbl_truthpred)

```









