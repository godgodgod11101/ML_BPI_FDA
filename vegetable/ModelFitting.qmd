---
title: "BPI Model Improvement"
author: "Jacky Wang"
format:
    html:
        theme: cosmo
        toc: true
        toc-depth: 2
        toc-location: right
        toc-title: "On this page"
        css: "css/style.css"
        df-print: paged
---



## Code Structure

1. 資料清理（DataWrangling.qmd）
2. 資料不平衡處理（HandlingImbData.qmd）
2. **模型配適（ModelFitting.qmd）**



## Introduction

本程式檔執行內容如下：

1. Import：引入資料，資料已進行清理與切分。
2. Handling Imbalanced Datasets：資料不平衡處理。



## Package

引入所需套件
```{r}
#| message: false
#| warning: false

# tidyverse
library(tibble)
library(dplyr)
library(purrr)    # FP toolkit，以map()、modify()取代for-loop

# tidymodels
library(parsnip)    # 配適模型的框架

```



## Import Data

```{r}
load(file = "data/vegetable_imb.rda")
```

```{r}
lst_mdlData$train_upsample %>% str(max.level = 1)
```



## Fit Models to Data

檢視模型可使用的引擎（配適模型的套件）
```{r}
show_engines("boost_tree")
# "logistic_reg", "naive_Bayes"
```

```{r}
#| message: false
#| warning: false
library(glmnet)    # Regularized Regression
library(xgboost)    # Gradient Boosting
library(klaR)    # Naive Bayes
library(discrim)    # parsnip extension package, to fit NB
```
[安裝xgboost](https://xgboost.readthedocs.io/en/stable/install.html#r)

### build

配合BPI模型設定
```{r}

lst_mdl <- list()    # 存放模型

# Elastic Net
lst_mdl[["enet"]] <- logistic_reg(penalty = 1e-4, mixture = 0.5) %>% 
    set_engine(engine = "glmnet")

# Gradient Boosting
lst_mdl[["gb"]] <- boost_tree(
    trees = 10, tree_depth = 5, learn_rate = 0.1, 
    sample_size = 1,    # 抽部分樣本
    mtry = NULL    # 抽部分特徵
) %>% 
    set_engine(
        engine = "xgboost", 
        objective = "binary:logistic",    # 以log-odds計算偽殘差
        reg_alpha = 0,    # L1正規化參數
        reg_lambda = 0,    # L2正規化參數
    ) %>% 
    set_mode(mode = "classification")

# Naive Bayes
lst_mdl[["nb"]] <- naive_Bayes(Laplace = 1) %>% 
    set_engine("klaR")

```

### fit

將模型配適於訓練集資料
```{r}
#| warning: false

# function
fit_mdls <- function(tbl_train) {
    
    # 一次訓練多個模型
    mdl_fit <- map(
        .x = lst_mdl, 
        .f = \(x) fit(x, formula = Y ~ ., data = tbl_train)
    )
    
    return(mdl_fit)
}

# execute
lst_fit <- list()    # 存放已配適資料的模型
lst_fit[["all"]] <- fit_mdls(lst_mdlData$train_upsample$all)
lst_fit[["130101"]] <- fit_mdls(lst_mdlData$train_upsample$`130101`)
lst_fit[["140703"]] <- fit_mdls(lst_mdlData$train_upsample$`140703`)

```



## Save

```{r}
save(lst_fit, file = "data/vegetable_fit.rda")
```





